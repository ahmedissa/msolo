Functionality:
 * macro syntax and substitution system
   * need to make the parser arbitrarily start on some piece of text and parse
     it out without assuming a template structure
     * need this when you are translating a block that doesn't have pure text
       and contains placeholders that need to be compiled
   * how to handle something like the #i18n block - it can be evaluated at
     compile time
   * want to save an intermediate representation to make it fast to do many
     versions of a single language
   * do you want to allow arbitrary nesting and tagging?
   * should you have a different (shorthand?) syntax for args?
     * could borrow the _() function from gettext
 * how do we do template import?
   * it's really going to be multiple inheritence, but can i make it less
     shady from a designer standpoint? maybe that's how i implement the 
     #include directive - but check at runtime that it's a library?
     * does that check buy you anything?
 * make #library directive to disambiguate template includes
 * allow #ifdef for compile time
 * import raw file include?
 * implement array slicing?
 * add native support for 'elif' clause
   * is this a codegen or parsing problem?
 * implement dictionary literals
 * implement support for True/False literals
 * while loop (repeat?) what is the difference?
 * test keyword args to functions with literals and complex placeholders
   * keyword syntax is ambiguous between definition and calling - using $
     should be more consistent. right now you must have it in the def, but you
     can't have it when you do the calling.
 * add #encoding directive
 * #set directive
 * add a build time/version attribute?
 * xhtml-oriented front end
   * emulate virtual odd/even var in loops (partially implemented Repeater)
 * Attribute Language - (like TAL and Kid)
   * guarantee well-formed
   * test attribute operator precedence
   * figure out nice way of inheritence
     * most TAL templates only use 1 level of inheritence
       * need to remember that most "subtemplates" are really complete,
         well formed xhtml documents, so it's hard to define function fragments
     * use processing instructions to create inheritance?
     * use py:def nodes to create "functions"?
   * add py:define
     * use pythonesqe syntax
     * syntax: py:define="x=$placeholder[0], y=$placeholder[1].my_attribute" 
   * add py:attributes
     * use exactly the same syntax as define?
     * syntax: py:attributes="x=$placeholder[0], y=$placeholder[1].my_attribute" 
     * use py-attr:<name>="expression" ?
       * creates yet another namespace - but might be the most logical

Optimization:
 * replace functions that only write a constant with one that just returns that
   constant string - no intermediate buffer
   * in some cases, might be able to skip the whole function call too
 * expose imports as globals vars that don't need to be resolved at runtime
 * factor out common sub-expressions during resolve_udn
 * only store local variables called more than once?
Variant 1:
        write(u"""<td>""") 
        write("%s" % column)
        write(u"""</td>\n""")

Variant 1.1:
        write(u"""<td>""") 
        write(str(column))
        write(u"""</td>\n""")

Variant 2:
        write(u"""<td>%s</td>\n""" % column)

   * optimization of this loop is dependend on the python version (2.4 vs 2.5)
   * Variant 2 is universally the slowest
 * collapse functions that comprise of a single text node to a return a unicode
   string constant

Cleanup:
 * revisit all uses of default_analyze_node - usually this is where
   unimplimented functionality lurks
 * front-end mode is a bit annoying - need to better detect xhtml vs text mode
   instead of passing around
 * analyzer is still a bit foul
   * want to make it possible to arbitrarily modify the tree without a copy
   * generic child_nodes array is probably no longer useful
   * how many times to I really have to make a copy of a node?
     * should I just modify inline after doing a tree-wise deep copy?
 * make the grammar file as simple as possible
 * why do i have 'code gen' in the semantic analysis phase? passing around
   variables etc for get_var/has_var seems ugly.
 * crunner is a bit foul - might be better to have separate front end for tests
   * borrow more code from spitfire-compile
 * EatPrevious node is a vile thing - make the DOM scanner look ahread 1 or 2
   nodes and determine what to do with optional whitespace nodes before
   processing them

Bugs:
 * py:conditional directives that are skipped still output a good amount of
   extra whitespace. could this be tightened up?
   
 * optional whitespace is not getting located correctly - the break statement
   seems to be confusing the parser
#for $x in $test_object_list
test line $x.id : $x.name
  #if $x.id > 1
    #break
  #end if
#end for

